{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2f23bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e204b35",
   "metadata": {},
   "source": [
    "Load smaller_LaBSE_15lang.\n",
    "\n",
    "The smaller LaBSE(language-agnostic BERT sentence embedding) is a patched version of google/LaBSE/2 to handle fewer languages.\n",
    "\n",
    "Support: Arabic, Chinese, English, French, German, Italian, Japanese, Korean, Dutch, Polish, Portuguese, Spanish, Thai, Turkish, Russian.\n",
    "\n",
    "Load preprocess and encoder.\n",
    "\n",
    "https://tfhub.dev/jeongukjae/smaller_LaBSE_15lang/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1947680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load if the files are saved on the computer\n",
    "LaBSE_preprocess=hub.KerasLayer(\"15lang_preprocess\")\n",
    "LaBSE_encoder=hub.KerasLayer(\"LaBSE_15\")\n",
    "\n",
    "# Loading models from tfhub.dev\n",
    "#LaBSE_encoder = hub.KerasLayer(\"https://tfhub.dev/jeongukjae/smaller_LaBSE_15lang/1\")\n",
    "#LaBSE_preprocess = hub.KerasLayer(\"https://tfhub.dev/jeongukjae/smaller_LaBSE_15lang_preprocess/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f77cfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_embedding_for_word(sentences):\n",
    "    sentences = tf.keras.layers.Input(shape=(), dtype=tf.string, name=\"sentences\")\n",
    "    encoder_inputs = LaBSE_preprocess(sentences)\n",
    "    sentence_representation = LaBSE_encoder(encoder_inputs)[\"pooled_output\"]\n",
    "    normalized_sentence_representation = tf.nn.l2_normalize(sentence_representation, axis=-1)  # for cosine similarity\n",
    "    model = tf.keras.Model(sentences, normalized_sentence_representation)\n",
    "    return model(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599cfa61",
   "metadata": {},
   "source": [
    "Divide the text into sequences and the next words.\n",
    "\n",
    "Example:\n",
    "\n",
    "    sentence = 'the boy who lived'.\n",
    "    \n",
    "    sequence=['the boy who'], next word='lived'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7636d0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Divide_text_file_into_sequences_and_next_words(file_path,language):\n",
    "    \n",
    "    #Dictionary of regular expression for wanted language.\n",
    "    #Thid dictionary is the only part of the code that needs editing in case of \n",
    "    #working with another language (which is supported by smaller_LaBSE_15lang)\n",
    "    regex_for_language = {\n",
    "        \"english\": \"[^a-zA-Z .]\",\n",
    "        \"russian\": \"[^А-я .]\"\n",
    "    }\n",
    "        \n",
    "    text = open(file_path,encoding=\"utf8\").read().lower()\n",
    "    text=re.sub(regex_for_language[language],'',text)\n",
    "    text=re.sub(' +',' ',text)\n",
    "    sentences=text.split('.')\n",
    "    sentences=[x for x in sentences if x]\n",
    "    sequences=[]\n",
    "    temp_labels=[]\n",
    "    for sentence in sentences:\n",
    "        sentence=sentence.strip()\n",
    "        temp_sentence=sentence.split(\" \")\n",
    "        for i in range(len(temp_sentence)):\n",
    "            s = [' '.join(temp_sentence[0:i+1])]\n",
    "            sequences.append(s)\n",
    "            temp_labels.append(temp_sentence[i])\n",
    "    temp_labels.pop(0)#Shift left the temp labels list (temp_labels is a list with the next word for each sequence in the text)\n",
    "    sequences.pop(-1)#delete the last sequences (there is no next word for it)\n",
    "    sequences=[x for x in sequences if x!=['']]\n",
    "    temp_labels=[x for x in temp_labels if x!='']\n",
    "    return sequences,temp_labels,sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9a47f4",
   "metadata": {},
   "source": [
    "# Text tokenization using keras Tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42fd3183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(sentences):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(sentences) #After the Tokenizer has been created, we then fit it on the data.\n",
    "    word_index = tokenizer.word_index #word index maps words in our vocabulary to their numeric representation.\n",
    "    total_unique_words = len(word_index) + 1 #number of words in vocabulary\n",
    "    return word_index,total_unique_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea90b0c",
   "metadata": {},
   "source": [
    "# Create vector for each label.\n",
    "\n",
    "(label is the next word for each sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46e71388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectors_for_labels(word_index,total_unique_words,temp_labels):\n",
    "    labels=[]\n",
    "    for i in range(len(temp_labels)):\n",
    "        lst=[0]*total_unique_words\n",
    "        lst[word_index[temp_labels[i]]]=1\n",
    "        labels.append(lst)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b37feb4",
   "metadata": {},
   "source": [
    "# Build dataset for Predicting the next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "661883ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset_for_predicting_the_next_word(file_path,language,optional_file_path=None):\n",
    "    sequences,temp_labels,sentences = Divide_text_file_into_sequences_and_next_words(file_path,language)\n",
    "    if optional_file_path:\n",
    "        optional_sequences,optional_temp_labels,optional_sentences = Divide_text_file_into_sequences_and_next_words(optional_file_path,language)\n",
    "        word_index,total_unique_words = tokenization(sentences+optional_sentences)\n",
    "        optional_labels = vectors_for_labels(word_index,total_unique_words,optional_temp_labels)\n",
    "        labels = vectors_for_labels(word_index,total_unique_words,temp_labels)\n",
    "        return sequences, labels, total_unique_words,optional_sequences,optional_labels\n",
    "    else:\n",
    "        word_index,total_unique_words = tokenization(sentences)\n",
    "        labels = vectors_for_labels(word_index,total_unique_words,temp_labels)\n",
    "        return sequences, labels, total_unique_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57215d2b",
   "metadata": {},
   "source": [
    "# Plot creation method for the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9eb9e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plot(history,wanted_history,data_set_type):\n",
    "    plt.plot(history.history[wanted_history])\n",
    "    plt.title('model '+ wanted_history)\n",
    "    plt.ylabel(wanted_history)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend([data_set_type], loc='upper left')\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c154dbc",
   "metadata": {},
   "source": [
    "# Build language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6287056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(intermediate_layer,total_unique_words,dropout_value=0.4,activation_function='softmax',learning_rate=0.0001,\n",
    "               loss_function='categorical_crossentropy'):\n",
    "    \n",
    "    #Dictionarie for the wanted intermediate_layer, 768 is the hidden size of LaBSE's sequence_output.\n",
    "    intermediate_layers = {\n",
    "        \"gru\": tf.keras.layers.GRU(768),\n",
    "        \"lstm\": tf.keras.layers.LSTM(768)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    text_input=tf.keras.layers.Input(shape=(),dtype=tf.string,name=\"input_layer\")\n",
    "    LaBSE_preprocessed_text=LaBSE_preprocess(text_input)\n",
    "    LaBSE_encoder_output=LaBSE_encoder(LaBSE_preprocessed_text)\n",
    "    \n",
    "    #\"sequence_output\": representations of every token in the input sequence with \n",
    "    #shape [batch size, max sequence length, hidden size(768)].\n",
    "    l=intermediate_layers[intermediate_layer](LaBSE_encoder_output['sequence_output'])\n",
    "    l=tf.keras.layers.Dropout(dropout_value,name='dropout')(l)\n",
    "    l=tf.keras.layers.Dense(total_unique_words,activation=activation_function,name='output')(l)\n",
    "\n",
    "    model=tf.keras.Model(inputs=[text_input],outputs=[l])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss=loss_function, metrics=['accuracy'])\n",
    "    model.summary() \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc728c9e",
   "metadata": {},
   "source": [
    "In the next section of the project\n",
    "\n",
    "#TBD#\n",
    "\n",
    "For research purposes, An experiment with 2 different intermediate layers will be performed - GRU and LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c544d72a",
   "metadata": {},
   "source": [
    "# Build train and test datasets for english tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "177adba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences,lables,total_unique_words = build_dataset_for_predicting_the_next_word(\"Harry Potter and the Philosophers Stone.txt\",\"english\")\n",
    "sequences_train, sequences_test, lables_train, lables_test = train_test_split(sequences, lables, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ec8848",
   "metadata": {},
   "source": [
    "# First NLP task - predict the next word.\n",
    "# [English,LSTM]\n",
    "Tuned the model to predict the next word in the sequence for english language.\n",
    "\n",
    "language: english.\n",
    "\n",
    "Text data: Harry Potter and the Philosophers Stone.\n",
    "\n",
    "Intermediate layer: LSTM.\n",
    "\n",
    "Frozen layers during the tuning: LaBSE embedding layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bdc481",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'englishLSTMNextWord'  \n",
    "if os.path.isdir(filename):# Checks if tuned model is exist.\n",
    "    model = keras.models.load_model(filename)  # If yes,load weights of the tuned model.\n",
    "else:#Else, tuned the model.\n",
    "    model = build_model(\"lstm\",total_unique_words)\n",
    "    train_history = model.fit(sequences_train, lables_train, epochs=1)\n",
    "    model.save(filename)  # Saves the weights of the tuned model for future use.\n",
    "    get_plot(train_history,'accuracy','train').show()\n",
    "    get_plot(train_history,'loss','train').show()\n",
    "\n",
    "score = model.evaluate(sequences_test, lables_test) \n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c787abb5",
   "metadata": {},
   "source": [
    "# Second NLP task - predict the next word.\n",
    "# [English,GRU]\n",
    "Tuned the model to predict the next word in the sequence for english language.\n",
    "\n",
    "language: english.\n",
    "\n",
    "Text data: Harry Potter and the Philosophers Stone.\n",
    "\n",
    "Intermediate layer: GRU.\n",
    "\n",
    "Frozen layers during the tuning: LaBSE embedding layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeb98a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'englishGRUNextWord'  \n",
    "if os.path.isdir(filename):# Checks if tuned model is exist.\n",
    "    model = keras.models.load_model(filename)  # If yes,load weights of the tuned model.\n",
    "else:#Else, tuned the model.\n",
    "    model = build_model(\"gru\",total_unique_words)\n",
    "    train_history = model.fit(sequences_train, lables_train, epochs=1)\n",
    "    model.save(filename)  # Saves the weights of the tuned model for future use.\n",
    "    get_plot(train_history,'accuracy','train').show()\n",
    "    get_plot(train_history,'loss','train').show()\n",
    "\n",
    "score = model.evaluate(sequences_test, lables_test) \n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9df2c90",
   "metadata": {},
   "source": [
    "In the next section of the project, the task is to examine whether a particular book was written by the author Mikhail Sholoshov.\n",
    "\n",
    "The model will tuned on a Поднятая целина (Podantia celina - russian-language book by the author mikhail sholokhov) and will be tested on Nachalen (russian-language book by the author mikhail sholokhov). \n",
    "\n",
    "The model will be tuned to predict the next word in a sequence for the train text - Podantia celina. The test will be performed on sequences from the russian book Nachalene.\n",
    "\n",
    "If the test score is high, it can assumed that the training book and the test book were written by the same author.\n",
    "\n",
    "For research purposes, An experiment with 2 different intermediate layers will be performed - GRU and LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b60427",
   "metadata": {},
   "source": [
    "# Build train and test datasets for russian tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1b83234",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences,train_lables,total_unique_words,test_sequences,test_labels = build_dataset_for_predicting_the_next_word(\"Поднятая целина.txt\",\"russian\",\"Nachalen.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf517a8",
   "metadata": {},
   "source": [
    "# Task - examine whether a particular book was written by the author Mikhail Sholoshov.\n",
    "# [Russian,GRU]\n",
    "Tuned the model to predict the next word in the sequence for Russian language.\n",
    "\n",
    "language: Russian.\n",
    "\n",
    "Train text data: Поднятая целина (Podantia celina - russian-language book by the author mikhail sholokhov).\n",
    "\n",
    "Test text data: Nachalen (russian-language book by the author mikhail sholokhov).\n",
    "\n",
    "Intermediate layer: GRU.\n",
    "\n",
    "Frozen layers during the tuning: LaBSE embedding layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb45cda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_layer (InputLayer)       [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       {'input_type_ids':   0           ['input_layer[0][0]']            \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_mask': (Non                                               \n",
      "                                e, 128)}                                                          \n",
      "                                                                                                  \n",
      " keras_layer_1 (KerasLayer)     {'encoder_outputs':  219171840   ['keras_layer[0][0]',            \n",
      "                                 [(None, 128, 768),               'keras_layer[0][1]',            \n",
      "                                 (None, 128, 768),                'keras_layer[0][2]']            \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768)],                                               \n",
      "                                 'pooled_output': (                                               \n",
      "                                None, 768),                                                       \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 128, 768)}                                                \n",
      "                                                                                                  \n",
      " gru (GRU)                      (None, 768)          3543552     ['keras_layer_1[0][13]']         \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 768)          0           ['gru[0][0]']                    \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 29520)        22700880    ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 245,416,272\n",
      "Trainable params: 26,244,432\n",
      "Non-trainable params: 219,171,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18356/1874067259.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;31m#Else, tuned the model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"gru\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtotal_unique_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtrain_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_sequences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_lables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrained_model_path\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Saves the weights of the tuned model for future use.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mget_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_history\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mflatten\u001b[1;34m(structure, expand_composites)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m   \u001b[0mexpand_composites\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpand_composites\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_model_path = 'russianGRUNextWord'  \n",
    "if os.path.isdir(trained_model_path):# Checks if tuned model is exist.\n",
    "    model = keras.models.load_model(trained_model_path)  # If yes,load weights of the tuned model.\n",
    "else:#Else, tuned the model.\n",
    "    model = build_model(\"gru\",total_unique_words)\n",
    "    train_history = model.fit(train_sequences, train_lables, epochs=1)\n",
    "    model.save(trained_model_path)  # Saves the weights of the tuned model for future use.\n",
    "    get_plot(train_history,'accuracy','train').show()\n",
    "    get_plot(train_history,'loss','train').show()\n",
    "\n",
    "score = model.evaluate(test_sequences, test_labels) \n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec05b836",
   "metadata": {},
   "source": [
    "# Task - examine whether a particular book was written by the author Mikhail Sholoshov.\n",
    "# [Russian,LSTM]\n",
    "Tuned the model to predict the next word in the sequence for Russian language.\n",
    "\n",
    "language: Russian.\n",
    "\n",
    "Train text data: Поднятая целина (Podantia celina - russian-language book by the author mikhail sholokhov).\n",
    "\n",
    "Test text data: Nachalen (russian-language book by the author mikhail sholokhov).\n",
    "\n",
    "Intermediate layer: LSTM.\n",
    "\n",
    "Frozen layers during the tuning: LaBSE embedding layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb5f8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_path = 'russianLSTMNextWord'  \n",
    "if os.path.isdir(trained_model_path):# Checks if tuned model is exist.\n",
    "    model = keras.models.load_model(trained_model_path)  # If yes,load weights of the tuned model.\n",
    "else:#Else, tuned the model.\n",
    "    model = build_model(\"lstm\",total_unique_words)\n",
    "    train_history = model.fit(train_sequences, train_lables, epochs=1)\n",
    "    model.save(trained_model_path)  # Saves the weights of the tuned model for future use.\n",
    "    get_plot(train_history,'accuracy','train').show()\n",
    "    get_plot(train_history,'loss','train').show()\n",
    "\n",
    "score = model.evaluate(test_sequences, test_labels) \n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffd05bd",
   "metadata": {},
   "source": [
    "prediction1=model.predict([\"Wonder how long Potter’s going to\"])\n",
    "prediction2=model.predict([\"You know how I think they\"])\n",
    "pca = PCA(n_components=2)\n",
    "x=np.array([prediction1[0], prediction2[0]], np.float32)\n",
    "reduced = pca.fit_transform(x)\n",
    "t = reduced.transpose()\n",
    "plt.scatter(t[0], t[1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
